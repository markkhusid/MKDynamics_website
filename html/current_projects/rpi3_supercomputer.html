<!DOCTYPE html>

<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-58919029-1', 'auto');
    ga('send', 'pageview');
</script>

<html>

<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <meta name="robots" content="follow" />
  
    <title>
        MK Dynamics - Raspberry Pi 3 Supercomputer
    </title>
  
    <link href="../css/styles.css" type = "text/css" rel = "stylesheet" />
  
    <style>
    .content {
	overflow: auto;
	height: 80%; 
	background: url("../images/galaxy1.jpg") no-repeat center center fixed;
	background-size: cover;
	background-position: center;
	padding: 10px;
	margin: 10px;
	border: 5px solid black;
      }
      
    h1, h2, h3, h4, p {
      color: white;
      display: block;     
    }
    
    object {
        margin          : 10px;
        padding-left    : 10px;
    }
    
    .current_project_1 {
      border		: 5px solid black;
      background	: gray;
      position		: relative;
      width		: 1250px;
      height		: 900px;
      top		: 0px;
      left		: 0px;
      float		: left;
      margin		: 10px;
      padding-left	: 10px;
    }
    
    .current_project_2 {
      border		: 5px solid black;
      background	: gray;
      position		: relative;
      width		: 1250px;
      height		: 900px;
      top		: 000px;
      left		: 0px;
      float		: left;
      margin		: 10px;
      padding-left	: 10px;
    }
    
    .current_project_3 {
      border		: 5px solid black;
      background	: gray;
      position		: relative;
      width		: 1250px;
      height		: 1400px;
      top		: 000px;
      left		: 0px;
      float		: left;
      margin		: 10px;
      padding-left	: 10px;
    }
    
    .current_project_4 {
      border		: 5px solid black;
      background	: gray;
      position		: relative;
      width		: 1250px;
      height		: 1400px;
      top		: 000px;
      left		: 0px;
      float		: left;
      margin		: 10px;
      padding		: 10px;
    }
    
    .current_project_5 {
      border		: 5px solid black;
      background	: gray;
      position		: relative;
      width		: 1250px;
      height		: 4000px;
      top		: 000px;
      left		: 0px;
      float		: left;
      margin		: 10px;
      padding		: 10px;
    }
    
    .current_project_6 {
      border		: 5px solid black;
      background	: gray;
      position		: relative;
      width		: 1250px;
      height		: 3800px;
      top		: 000px;
      left		: 0px;
      float		: left;
      margin		: 10px;
      padding		: 10px;
    }
    
    div .img {
      margin		: 0px;
      padding		: 10px;
      height		: auto;
      width		: auto;
      float		: left;
    }
    
    div .img img {
      display		: inline;
      margin		: 0px;
      padding		: 0px;
    }
    
    div .desc {
      color		: white;
      width		: 600px;
      margin		: 5px;
      padding		: 10px;
    }
    
    ul {
      color		: white;
    }
    
    div .loose_text {
      color		: white;
    }
  </style>
</head>

<body>
  <div class="wrapper">
    <header>
    
      <hgroup>
	<h1> 
	    <big> <big> MK Dynamics </big> </big>
	</h1>


	<h2>
	  Raspberry Pi 3 Supercomputer - Main Page
	</h2>
      </hgroup>
    

      <nav>
	<ul>
	  <li> <a href="../index.html">Home</a> </li>
	</ul>
      </nav>
  
      <hr />
    
    </header>
    
  

    <section class="content">
    
        <section class="first_section">
        
            <div class="current_project_1">
            
                <div class="img">
                
                    <img
                        src="images/rpi-beowulf-cluster.png"
                        width="1200"
                        height="800"
                        title="rpi-beowulf-cluster.png"
                    >
                    
                </div> <!-- .img -->
	  
                <div class="loose_text">
                    http://hackaday.com/2013/05/21/33-node-beowulf-cluster-built-with-raspberry-pi/<br>
                    <a href="http://hackaday.com/2013/05/21/33-node-beowulf-cluster-built-with-raspberry-pi/">An example of a Raspberry Pi supercomputer cluster</a>
                </div> <!-- .loose_text -->
        
            </div> <!-- .current_project_1 -->
            
        </section> <!-- first_section -->
    
     
        <section class="second_section">
        
            <div class="current_project_2">
            
                <hgroup>
                
                    <h1>
                        <big> <big> Description </big> </big>
                    </h1>
                    
                    <h2>
                        Introduction
                    </h2>
                    
                <hgroup>

            <div class="loose_text">
                <p>
                    For this project, we will be building a multiprocessor supercomputer based on the Raspberry Pi 3.  We will use the Single Program Multiple Data architecture to perform multiphysics simulations of various problems of interest, such as colliding galaxies, continuous Fast Fourier Transforms of acquired radio spectrum, and image processing of astronomical photos.  During other times, the cluster will be running BOINC processes.  Specifically, it will be running SETI@Home and Einstein@Home.
                </p>
            
                <p>
                    Supercomputing architecures come in multiple forms.  A good discussion of these can be found here.<br>
                    <a href="https://en.wikipedia.org/wiki/Parallel_computing">https://en.wikipedia.org/wiki/Parallel_computing</a>
                </p>
            
                <p>
                    Our programming languages of choice are Fortran and Python.  Fortran has a number of mechanisms for facilitating parallel computing, namely Message Passing Interface (MPI) and Coarrays.  Information on MPI in Fortran can be found here:<br>
                    <a href="http://condor.cc.ku.edu/~grobe/docs/intro-MPI.shtml">http://condor.cc.ku.edu/~grobe/docs/intro-MPI.shtml</a>
                </p>
            
                <p>
                    Information on Fortran Coarrays can be found here:<br>
                    <a href="https://en.wikipedia.org/wiki/Coarray_Fortran">https://en.wikipedia.org/wiki/Coarray_Fortran</a><br>
                    <a href="http://www.eneagrid.enea.it/tutorial/fanfarillo2014/AFanfarillo_20141219_CoarrayENEA.pdf">http://www.eneagrid.enea.it/tutorial/fanfarillo2014/AFanfarillo_20141219_CoarrayENEA.pdf</a>
                </p>
            
                <p>
                    While there are a number of parallel computing enabled Fortran compilers available, the author's preference is to use all open-source hardware and software.  A Fortran compiler that fits this criteria is the GNU Fortran compiler with either the OpenCoarrays or OpenMPI extensions and libraries, which can be found here:<br>
                    <a href="https://gcc.gnu.org/wiki/GFortran">https://gcc.gnu.org/wiki/GFortran</a><br>
                    <a href="http://www.opencoarrays.org/">http://www.opencoarrays.org/</a><br>
                    <a href="https://www.open-mpi.org/">https://www.open-mpi.org/</a><br>
                </p>
                
                <p>
                    Our development environment of choice is Eclipse IDE, with the Parallel Tools Platform.  The current version of the Eclipse IDE is called NEON, and can be downloaded from here: <br>
                    <a href="https://eclipse.org/home/index.php">https://eclipse.org/home/index.php</a><br>
                </p>
                
                <p>
                    Supercomputer clusters of Raspberry Pi's have been built by many people as can be seen from a Google search.  Many have built these from the Versions Zero, 1, and 2 of the Raspberry Pi.  With the advent of the Raspberry Pi 3, it has been noted by many that it's CPU can reach much higher temperatures than it's predecessors.  It has also been noted that the CPU contains a speed governor that reduces the clock rate once the core temperature reaches 85 Celcius.
                </p>
            
                <p>
                    We obviously wish to avoid temperature induced throttling of the CPU in order to maximize supercomputing performance.  Additionally, we wish to avoid large quantities of small fans on each of the individual Raspberry Pi's.  Several have suggested a water cooled system.  In our estimation, this will contain a cold fluid supply rail, a hot fluid return rail, radiator, reservoir / pump combination, and all of the associated plumbing.  A fan of appropriate air flow rate will supply cooling air to the radiator.
                </p>
                
            </div> <!-- .loose-tect -->
            
        </div> <!-- .current_project_2 -->
        
    </section> <!-- second_section --> 
    

    <section class="third_section">
    
        <div class="current_project_3">
            <hgroup>
                <h2>
                    Watercooled Heatsink Analysis, Design and Thermal Modeling
                </h2>
            </hgroup>
            
            <br><br><br>
            
            <hgroup>
                <h3>
                    Watercooled Heatsink Analysis and Design
                </h3>
            </hgroup>
            <div class="loose_text">
            
                <p>
                    In what follows, we will analyze the thermal characteristics of the Raspberry Pi 3 and design an appropriate water cooling system for the supercomputer cluster.  We will try to calculate the thermal impedance of the Raspberry Pi 3's CPU chip, since vendor supplied datasheets are not available.  We use data gathered from various sources on the Internet.  We will then use these calculations to estimate the required parameters of our water cooling system.
                </p>
            
            </div> <!-- .loose-text -->
        
            <figure>
                <img
                    src="images/RPi3 Thermal Calcs_12.png"
                    width="600px"
                    height="400px"
                    title="RPi3 Thermal Calcs_12.png"
                >
	    
                <figcaption>
                    <a href="watercooled_heatsink_calcs.html">Watercooled Heatsink Analysis and Design</a><br>
                </figcaption>
                
            </figure>
            
            <br><br><br>
            
            <hgroup>
                <h3>
                    Finite Element Modeling of the Watercooled Heatsink
                </h3>
            </hgroup>
            
            <div class="loose_text">
                
                <p>
                    After performing calculations to obtain the performance of the watercooled heatsink, and getting an estimate for the required flow rate and radiator characteristics, we will now perform Finite Element Modeling of the design using Salome Meca + Code Aster FEM software.
                </p>
            
            </div> <!-- .loose_text -->
            
            <figure>
                <img
                    src="images/thermal_study1.jpeg"
                    width="600px"
                    height="400px"
                    title="thermal_study1.jpeg"
                >
                
                <figcaption>
                    <a href="FEM_thermal_modeling.html">Finite Element Modelling Thermal Analysis</a><br>
                </figcaption>
            </figure>

        </div> <!-- .current_project_3 -->
        
    </section> <!-- .third_section -->

    <section class="fourth_section">
    
        <div class="current_project_4">
        
            <hgroup>
                <h2>
                    Fortran Programing for Multiprocessor Supercomputer
                </h2>
            </hgroup>
            
            <br><br><br>
            
            <hgroup>
                <h3>
                    Fortran Programming with OpenMPI
                </h3>
            </hgroup>
            
            <div class="loose_text">
                <p>
                    In this section, we will write multiprocessor execution Fortran code using the OpenMPI library.
                </p>
            </div> <!-- .loose_text -->
            
            <figure>
                <img
                    src="images/multicore_processor.jpeg"
                    width="600px"
                    height="400px"
                    title="multicore_processor.jpeg"
                >
                
                <figcaption>
                    <a href="parallel_Fortran_code_OMPI.html">Fortran Programming with MPI</a><br>
                </figcaption>
            
            </figure>
            
            
            
            <br><br><br>
            
            <hgroup>
                <h3>
                    Fortran Programming with Coarrays
                </h3>
            </hgroup>
            
            <div class="loose_text">
                
                <p>
                    In this section, we will write multiprocessor Fortran code using Fortran's coarray features for multiprocessor execution.
                </p>
            
            </div> <!-- .loose_text -->
            
            <figure>
                <img
                    src="images/early_cray.jpeg"
                    width="600px"
                    height="400px"
                    title="early_cray.jpeg"
                >
                
                <figcaption>
                    <a href="parallel_Fortran_code_OCA.html">Fortran Programming with Coarrays</a><br>
                </figcaption>
                
            </figure>
            
            
            
        </div> <!-- .current_project_4 -->
        
    </section> <!-- .fourth_section -->

        
    </section>	<!-- .content -->
    
  </div> <!-- .wrapper -->

  </body>

</html>
  

